{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c620ae",
   "metadata": {},
   "source": [
    "# Gemini API intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make decisions and perform tasks.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# looks automatically after the key\n",
    "# one of GOOGLE_API_KEY and GEMINI_API_KEY\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Explain how AI works in a few words\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d518e4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 data engineering jokes, structured in short points:\n",
      "\n",
      "1.  A data engineer's job is 10% coding, 90% debugging why the data from the 'clean' source looks like it was generated by a toddler with a keyboard.\n",
      "2.  What's a data engineer's biggest fear? A fully automated data pipeline... that actually works for more than a day.\n",
      "3.  Heard a data engineer say they finished their project. I almost choked on my coffee – that's like saying you've finished eating a never-ending buffet.\n",
      "4.  A data scientist walks into a bar and asks for a perfectly clean, curated dataset. The bartender says, \"Sorry, we only serve real-world data here.\"\n",
      "5.  My data pipeline isn't broken, it's just... *exercising its right to unpredictability*.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ask_gemini(prompt, model = \"gemini-2.5-flash\"):\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=prompt,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "response = ask_gemini(\"Give me 5 some data engineering jokes, structure it in short points\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b30203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# knows that GenerateContentResponse is a pydantic model\n",
    "# -> we can work with it in a OOP manner\n",
    "isinstance(response, BaseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0feccb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sdk_http_response', 'candidates', 'create_time', 'model_version', 'prompt_feedback', 'response_id', 'usage_metadata', 'automatic_function_calling_history', 'parsed'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97ff570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini-2.5-flash'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c04e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HttpResponse(\n",
       "  headers=<dict len=11>\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sdk_http_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "078632a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(\n",
       "   content=Content(\n",
       "     parts=[\n",
       "       Part(\n",
       "         text=\"\"\"Here are 5 data engineering jokes, structured in short points:\n",
       " \n",
       " 1.  A data engineer's job is 10% coding, 90% debugging why the data from the 'clean' source looks like it was generated by a toddler with a keyboard.\n",
       " 2.  What's a data engineer's biggest fear? A fully automated data pipeline... that actually works for more than a day.\n",
       " 3.  Heard a data engineer say they finished their project. I almost choked on my coffee – that's like saying you've finished eating a never-ending buffet.\n",
       " 4.  A data scientist walks into a bar and asks for a perfectly clean, curated dataset. The bartender says, \"Sorry, we only serve real-world data here.\"\n",
       " 5.  My data pipeline isn't broken, it's just... *exercising its right to unpredictability*.\"\"\"\n",
       "       ),\n",
       "     ],\n",
       "     role='model'\n",
       "   ),\n",
       "   finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "   index=0\n",
       " )]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904d18b",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "\n",
    "- basic unit of text for LLMs\n",
    "- can be as short as one character or as long as one word\n",
    "\n",
    "- tokens used for billing\n",
    "\n",
    "Gemini free tier \n",
    "- Requests per minute (RPM): 10\n",
    "- Tokens per minute (TPM): 250 000\n",
    "- Requests per day (RPD): 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a1c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=187,\n",
       "  prompt_token_count=15,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=15\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=1197,\n",
       "  total_token_count=1399\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thinking is expensive\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d634c1c8",
   "metadata": {},
   "source": [
    "## Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a616ff03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 data engineering jokes, structured in short points:\n",
      "\n",
      "1.  **A data engineer walks into a bar.**\n",
      "    *   Orders a beer.\n",
      "    *   Bartender asks, \"Want to denormalize that?\"\n",
      "\n",
      "2.  **Why did the ELT job get fired?**\n",
      "    *   It kept asking \"Why transform now?\"\n",
      "\n",
      "3.  **What's a data engineer's favorite type of music?**\n",
      "    *   Pipelines, especially when they're flowing!\n",
      "\n",
      "4.  **A data scientist, a data analyst, and a data engineer are on a plane.**\n",
      "    *   The plane crashes.\n",
      "    *   Who survives? The data engineer, because they built the emergency parachute system that everyone else just *assumed* was working.\n",
      "\n",
      "5.  **Heard about the data engineer who tried to automate everything?**\n",
      "    *   His morning coffee ran through a DAG.\n",
      "    *   But the downstream tasks kept failing because the beans weren't idempotently roasted.\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "prompt = \"Give me 5 some data engineering jokes, structure it in short points\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11f49955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=219,\n",
       "  prompt_token_count=15,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=15\n",
       "    ),\n",
       "  ],\n",
       "  total_token_count=234\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657eed4",
   "metadata": {},
   "source": [
    "## System instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "233f842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**OOP (Object-Oriented Programming):**\n",
      "\n",
      "*   Organizes code around \"objects\" (data + behavior).\n",
      "*   Key principles:\n",
      "    *   **Encapsulation:** Bundling data and methods.\n",
      "    *   **Inheritance:** Creating new classes from existing ones.\n",
      "    *   **Polymorphism:** Objects taking on many forms.\n",
      "    *   **Abstraction:** Hiding complex implementation.\n",
      "\n",
      "**Dunder (Double Underscore) Methods:**\n",
      "\n",
      "*   Special methods with double underscores (e.g., `__init__`, `__str__`).\n",
      "*   Used for operator overloading, object initialization, string representation, etc.\n",
      "*   Allow you to customize how objects behave in various situations (e.g., when added, printed).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_instruction = \"\"\"\n",
    "You are an expert in python programming, you will always provide idiomatic code, i.e.\n",
    "pythonic code. So when you see my code or my question, be very critical, but answer\n",
    "in a SHORT and CONCISE way. Also be constructive to help me improve. \n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Explain OOP and dunder methods.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instruction\n",
    "        # thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23cd72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-kokchun-giang-de24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
